{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c54141",
   "metadata": {},
   "source": [
    "## Spam Email Classifier with KNN using TF-IDF scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17102e",
   "metadata": {},
   "source": [
    "1.   Assignment must be implemented in Python 3 only.\n",
    "2.   You are allowed to use libraries for data preprocessing (numpy, pandas, nltk etc) and for evaluation metrics, data visualization (matplotlib etc.).\n",
    "3.   You will be evaluated not just on the overall performance of the model and also on the experimentation with hyper parameters, data prepossessing techniques etc.\n",
    "4.   The report file must be a well documented jupyter notebook, explaining the experiments you have performed, evaluation metrics and corresponding code. The code must run and be able to reproduce the accuracies, figures/graphs etc.\n",
    "5.   For all the questions, you must create a train-validation data split and test the hyperparameter tuning on the validation set. Your jupyter notebook must reflect the same.\n",
    "6.   Strict plagiarism checking will be done. An F will be awarded for plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d34a310",
   "metadata": {},
   "source": [
    "**Task: Given an email, classify it as spam or ham**\n",
    "\n",
    "Given input text file (\"emails.txt\") containing 5572 email messages, with each row having its corresponding label (spam/ham) attached to it.\n",
    "\n",
    "This task also requires basic pre-processing of text (like removing stopwords, stemming/lemmatizing, replacing email_address with 'email-tag', etc..).\n",
    "\n",
    "You are required to find the tf-idf scores for the given data and use them to perform KNN using Cosine Similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c87696",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d5a1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef4dff",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f178f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emails.txt', 'r') as inFile:\n",
    "    email_texts = inFile.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ef5ba",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd1733d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "raw_data = list()\n",
    "for line in email_texts:\n",
    "    word_list = line.strip().split()[1:]\n",
    "    temp = list()\n",
    "    for w in word_list:\n",
    "        w = w.lower()\n",
    "        for p in string.punctuation:\n",
    "            w = w.replace(p, '')\n",
    "\n",
    "        if(w not in stop_words and w not in string.digits):\n",
    "            temp.append(ps.stem(w))\n",
    "\n",
    "    raw_data.append({ 'label': line.strip().split()[0], 'data': temp })\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76767a7",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f75e6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df.sample(frac=1.0, random_state=69)\n",
    "split_idx1 = math.ceil(0.6 * len(df))\n",
    "split_idx2 = math.ceil(0.8 * len(df))\n",
    "\n",
    "train_data_set = df_data[:split_idx1]\n",
    "validate_data_set = df_data[split_idx1:split_idx2]\n",
    "test_data_set = df_data[split_idx2:]\n",
    "\n",
    "train_data_set.reset_index(inplace=True)\n",
    "train_data_set = train_data_set.drop('index', axis=1)\n",
    "\n",
    "validate_data_set.reset_index(inplace=True)\n",
    "validate_data_set = validate_data_set.drop('index', axis=1)\n",
    "\n",
    "test_data_set.reset_index(inplace=True)\n",
    "test_data_set = test_data_set.drop('index',axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6eb76b",
   "metadata": {},
   "source": [
    "### Train your KNN model (reuse previously iplemented model built from scratch) and test on your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22baf6b2",
   "metadata": {},
   "source": [
    "***1. Experiment with different distance measures [Euclidean distance, Manhattan distance, Hamming Distance] and compare with the Cosine Similarity distance results.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea0a2a",
   "metadata": {},
   "source": [
    "- Calculation of IDF on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68f1bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574\n"
     ]
    }
   ],
   "source": [
    "train_data_idf = dict()\n",
    "for line in train_data_set['data']:\n",
    "    words = set(line)\n",
    "    for w in words:\n",
    "        if w not in train_data_idf:\n",
    "            train_data_idf[w] = 1\n",
    "        else:\n",
    "            train_data_idf[w] = train_data_idf[w] + 1\n",
    "no_of_docs = df.shape[0]\n",
    "print(no_of_docs)\n",
    "for key in train_data_idf:\n",
    "    train_data_idf[key] = math.log(no_of_docs/(1+train_data_idf[key]))\n",
    "\n",
    "# pd.DataFrame([train_data_idf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b4dcb",
   "metadata": {},
   "source": [
    "- Calculation of TF (Term frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d31c167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf(line):\n",
    "    \"\"\"\n",
    "    Fn calculates TF value of each word present in a sentence,\n",
    "    passed as list of words (tokenized form)\n",
    "    \n",
    "    @params:\n",
    "        line: list of words\n",
    "    \n",
    "    @return:\n",
    "        dict: key as word, value as TF value\n",
    "    \"\"\"\n",
    "    tf = dict()\n",
    "    for key in train_data_idf:\n",
    "        tf[key] = 0\n",
    "\n",
    "    for w in line:\n",
    "        if w in tf:\n",
    "            tf[w] = tf[w] + 1\n",
    "\n",
    "    for w in tf:\n",
    "        if len(line) != 0:\n",
    "            tf[w] = tf[w]/len(line)\n",
    "    \n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e28006",
   "metadata": {},
   "source": [
    "- TF-IDF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80877264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(idf, data_set):\n",
    "    \"\"\"\n",
    "    Fn calculates TF-IDF value of each word present in argument data_set,\n",
    "    using IDF value passed as argument.\n",
    "\n",
    "    @params:\n",
    "        idf: \n",
    "            dict: key as word, value as IDF value\n",
    "        data_set:\n",
    "            list of object with keys as 'label':string \n",
    "            and 'data': list of word for each sentence\n",
    "    \n",
    "    @return:\n",
    "        np array: list of 1D array as TF-IDF of each word in a sentence of data_set\n",
    "    \"\"\"\n",
    "    tf_idf_dict = list()\n",
    "\n",
    "    for line in data_set['data']:\n",
    "        # if len(line) != 0:\n",
    "        tf = calc_tf(line)\n",
    "        for k in tf:\n",
    "            tf[k] = tf[k] * idf[k]\n",
    "        tf_idf_dict.append(tf)\n",
    "        \n",
    "    tf_idf = list()\n",
    "    for d in tf_idf_dict:\n",
    "        temp = list()\n",
    "        for w in d:\n",
    "            temp.append(d[w])\n",
    "        tf_idf.append(temp)\n",
    "\n",
    "    return np.array(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e62456",
   "metadata": {},
   "source": [
    "- Calculation of TF-IDF of all data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc3d3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = get_tf_idf(train_data_idf, train_data_set)\n",
    "tf_idf_test = get_tf_idf(train_data_idf, test_data_set)\n",
    "tf_idf_validate = get_tf_idf(train_data_idf, validate_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f45d58",
   "metadata": {},
   "source": [
    "- Similarity Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31a15bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(train_list, test_list):\n",
    "    return dot(train_list, test_list)/(norm(train_list)*norm(test_list))\n",
    "\n",
    "\n",
    "def euclidean_dist(train_list, test_list):\n",
    "    return norm(train_list - test_list)\n",
    "\n",
    "\n",
    "def manhattan_dist(train_list, test_list):\n",
    "    return np.abs(train_list - test_list).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbdff167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_obj_list(sim_fn, data_set, tf_idf):\n",
    "    \"\"\"\n",
    "    This function calculates similarities/distances for passed data_set using train_data_set.\n",
    "\n",
    "    @params:\n",
    "        sim_fn: int\n",
    "            1 for Cosine Similarity\n",
    "            2 for Eucledian Distance\n",
    "            3 for Manhattan Distance\n",
    "        data_set: list\n",
    "            list of object with keys as 'label':string \n",
    "            and 'data': list of word for each sentence\n",
    "        tf_idf: 2D list\n",
    "            TF-IDF of passed data_set\n",
    "\n",
    "    @return:\n",
    "        list of object as,\n",
    "            key : label, \n",
    "            value : list of tuples having (label, its similarity value) \n",
    "                    for each item in data_set\n",
    "    \"\"\"\n",
    "    res = list()\n",
    "\n",
    "    for x, data_item in data_set.iterrows():\n",
    "        tmp_dict = dict()\n",
    "        tmp_list = list()\n",
    "        for y, train_data in train_data_set.iterrows():\n",
    "            sim_val = 0\n",
    "            if sim_fn == 1:\n",
    "                sim_val = 1 - cosine_sim(tf_idf_train[y], tf_idf[x])\n",
    "            elif sim_fn == 2:\n",
    "                sim_val = euclidean_dist(tf_idf_train[y], tf_idf[x])\n",
    "            else:\n",
    "                sim_val = manhattan_dist(tf_idf_train[y], tf_idf[x])\n",
    "\n",
    "            tmp_list.append((train_data['label'], sim_val))\n",
    "\n",
    "        tmp_dict[data_item['label']] = sorted(tmp_list, key = lambda i : i[1])\n",
    "        res.append(tmp_dict)\n",
    "\n",
    "    return res\n",
    "    \n",
    "\n",
    "# def get_accuracy_ratio(k, sim_fn):\n",
    "#     \"\"\"\n",
    "#     @params: k-value, similarity funtion selector\n",
    "#     @return: accuracy ratio\n",
    "#     \"\"\"\n",
    "#     test_train_cos_sim = get_similarity_obj_list(k, sim_fn)\n",
    "#     right_count = 0\n",
    "#     for res_data in test_train_cos_sim:\n",
    "#         for label in res_data:\n",
    "#             correct_ratio = 0\n",
    "#             for arr_elem in res_data[label][:k]:\n",
    "#                 if(arr_elem[0] == label):\n",
    "#                     correct_ratio += 1\n",
    "#             if(correct_ratio/k) >= 0.5:\n",
    "#                 right_count += 1\n",
    "\n",
    "#     return right_count/len(test_train_cos_sim)\n",
    "\n",
    "\n",
    "def get_truth_predict_tuple_list(k, dict_list):\n",
    "    \"\"\"\n",
    "    This Fn calculates predicted value using k-value\n",
    "    @params: \n",
    "        k-value: int, \n",
    "        dict_list: list\n",
    "            list of dict having key as label (truth value) and\n",
    "            key as list of tuples having (label, similarity value\n",
    "\n",
    "    @return: list of tuple as (truth value, predicted value)\n",
    "    \"\"\"\n",
    "    resp = list()\n",
    "    for res_data in dict_list:\n",
    "        for label in res_data:\n",
    "            ham_count = 0\n",
    "            spam_count = 0\n",
    "            # for arr_elem in res_data[label][:k]:\n",
    "            for idx in range(k):\n",
    "                arr_elem = res_data[label][idx]\n",
    "                if(arr_elem[0] == 'spam'):\n",
    "                    spam_count += 1\n",
    "                else:\n",
    "                    ham_count += 1\n",
    "\n",
    "            if(spam_count > ham_count):\n",
    "                resp.append((label, 'spam'))\n",
    "            else:\n",
    "                resp.append((label, 'ham'))\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d2719cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(k, dict_list):\n",
    "    \"\"\"\n",
    "    @params: \n",
    "        k: int\n",
    "            k-value,\n",
    "        dict_list: list\n",
    "            list of dict having key as label (truth value) and\n",
    "            key as list of tuples having (label, similarity value\n",
    "        \n",
    "    @return: int\n",
    "        f1 score value\n",
    "    \"\"\"\n",
    "    tuple_list = get_truth_predict_tuple_list(k, dict_list)\n",
    "\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    for it in tuple_list:\n",
    "        if(it[0] == 'spam'):\n",
    "            if(it[0] == it[1]):\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        else:\n",
    "            if(it[0] == it[1]):\n",
    "                true_negative += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "\n",
    "    # return [[true_positive, false_negative], [false_positive, true_negative]]\n",
    "\n",
    "    precision = 0\n",
    "    if (true_positive + false_positive) != 0:\n",
    "        precision = true_positive/float(true_positive + false_positive)\n",
    "\n",
    "    recall = 0\n",
    "    if (true_positive + false_negative) != 0:\n",
    "        recall = true_positive/float(true_positive + false_negative)\n",
    "\n",
    "    f1_score = 0\n",
    "    if (precision + recall) != 0:\n",
    "        f1_score = 2 * ((precision * recall)/float(precision + recall))\n",
    "    \n",
    "    return f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "183d2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_score(k, dict_list):\n",
    "    \"\"\"\n",
    "    @params: \n",
    "        k: int\n",
    "            k-value,\n",
    "        dict_list: list\n",
    "            list of dict having key as label (truth value) and\n",
    "            key as list of tuples having (label, similarity value\n",
    "        \n",
    "    @return: int\n",
    "        accuracy score\n",
    "    \"\"\"\n",
    "    tuple_list = get_truth_predict_tuple_list(k, dict_list)\n",
    "\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    for it in tuple_list:\n",
    "        if(it[0] == 'spam'):\n",
    "            if(it[0] == it[1]):\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        else:\n",
    "            if(it[0] == it[1]):\n",
    "                true_negative += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "\n",
    "    # return [[true_positive, false_negative], [false_positive, true_negative]]\n",
    "\n",
    "    # precision = 0\n",
    "    # if (true_positive + false_positive) != 0:\n",
    "    #     precision = true_positive/float(true_positive + false_positive)\n",
    "\n",
    "    # recall = 0\n",
    "    # if (true_positive + false_negative) != 0:\n",
    "    #     recall = true_positive/float(true_positive + false_negative)\n",
    "\n",
    "    # f1_score = 0\n",
    "    # if (precision + recall) != 0:\n",
    "    #     f1_score = 2 * ((precision * recall)/float(precision + recall))\n",
    "\n",
    "    accuracy_score = (true_positive + true_negative)/float(true_negative + true_positive + false_negative + false_positive)\n",
    "    \n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6f3b1",
   "metadata": {},
   "source": [
    "***2. Explain which distance measure works best and why? Explore the distance measures and weigh their pro and cons in different application settings.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae57a01",
   "metadata": {},
   "source": [
    "\n",
    "In our dataset, we see that we get the best accuracy scores by using **cosine simmilarity**, in comparison of euclidean and manhattan distances.\n",
    "\n",
    "The cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean/Manhattan distances, they could still have a smaller angle between them. Smaller the angle, higher the cosine similarity.\n",
    "\n",
    "Cosine similarity is calculated using only the dot product and magnitude of each vector, and is therefore affected only by the terms the two vectors have in common.\n",
    "\n",
    "- Pros:\n",
    "    Both continuous and categorical variables can be used.\n",
    "- Cons:\n",
    "    Doesn’t work efficiently with nominal data.\n",
    "- Significant Application Area:\n",
    "    Text Mining\n",
    "\n",
    "**Euclidean Distance** is the ordinary distance between a pair of objects which can be measured with the help of a ruler.\n",
    "\n",
    "- Pros:\n",
    "    Easy to implement. Easy to test.\n",
    "\n",
    "- Cons:\n",
    "    The variables which have the largest value greatly influence the result. Doesn’t work efficiently with image data.\n",
    "\n",
    "- Significant Application Area:\n",
    "    Application involving Interval Data, DNA Analysis, Health Psychology Analysis\n",
    "\n",
    "**Manhattan Distance** is the distance between a pair of points which is measured along the axes at 90 degrees or right angles.\n",
    "\n",
    "- Pros\n",
    "    Easy to generalize into higher dimensions.\n",
    "\n",
    "- Cons:\n",
    "    Doesn’t work efficiently with image data. Can’t be used to classify documents.\n",
    "\n",
    "- Significant Application Area:\n",
    "    Integrated Circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a99c76",
   "metadata": {},
   "source": [
    "***3. Report Mean Squared Error(MSE), Mean-Absolute-Error(MAE), R-squared (R2) score in a tabular form***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9668814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4dde8d3",
   "metadata": {},
   "source": [
    "***4. Choose different K values (k=1,3,5,7,11,17,23,28) and experiment. Plot a graph showing F1 score vs k.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad0275fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/1760g61j5qv_09twk6bg40kh0000gn/T/ipykernel_74822/1941715078.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return dot(train_list, test_list)/(norm(train_list)*norm(test_list))\n"
     ]
    }
   ],
   "source": [
    "k_val_range = [1,3,5,7,11,17,23,28]\n",
    "f1_val_list_cos_sim = list()\n",
    "f1_val_list_euc_dist = list()\n",
    "f1_val_list_man_dist = list()\n",
    "\n",
    "validate_train_sim_dict = get_similarity_obj_list(1, validate_data_set, tf_idf_validate)\n",
    "validate_train_euc_dict = get_similarity_obj_list(2, validate_data_set, tf_idf_validate)\n",
    "validate_train_man_dict = get_similarity_obj_list(3, validate_data_set, tf_idf_validate)\n",
    "\n",
    "for k in k_val_range:\n",
    "    f1_val_list_cos_sim.append(get_f1_score(k, validate_train_sim_dict))\n",
    "    f1_val_list_euc_dist.append(get_f1_score(k, validate_train_euc_dict))\n",
    "    f1_val_list_man_dist.append(get_f1_score(k, validate_train_man_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22fe45",
   "metadata": {},
   "source": [
    "- Graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45e0fd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('K value')\n",
    "plt.ylabel('F1 score')\n",
    "plt.title(\"F1 Score vs K-value\")\n",
    "plt.scatter(k_val_range, f1_val_list_cos_sim, label='Cosine Sim', color='red')\n",
    "plt.scatter(k_val_range, f1_val_list_euc_dist, label='Eucledian Dist', color='blue')\n",
    "plt.scatter(k_val_range, f1_val_list_man_dist, label='Manhattan Dist', color='green')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700239e",
   "metadata": {},
   "source": [
    "- Calculation of optimal k-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2cf9417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k_val = 0\n",
    "max_f1 = 0\n",
    "optimal_sim_fn = 1\n",
    "\n",
    "for i,v in enumerate(f1_val_list_cos_sim):\n",
    "    if max_f1 < v and k_val_range[i] != 1:\n",
    "        max_f1 = v\n",
    "        optimal_k_val = k_val_range[i]\n",
    "        optimal_sim_fn = 1\n",
    "\n",
    "for i,v in enumerate(f1_val_list_euc_dist):\n",
    "    if max_f1 < v and k_val_range[i] != 1:\n",
    "        max_f1 = v\n",
    "        optimal_k_val = k_val_range[i]\n",
    "        optimal_sim_fn = 2\n",
    "\n",
    "for i,v in enumerate(f1_val_list_man_dist):\n",
    "    if max_f1 < v and k_val_range[i] != 1:\n",
    "        max_f1 = v\n",
    "        optimal_k_val = k_val_range[i]\n",
    "        optimal_sim_fn = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/1760g61j5qv_09twk6bg40kh0000gn/T/ipykernel_74822/1941715078.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return dot(train_list, test_list)/(norm(train_list)*norm(test_list))\n"
     ]
    }
   ],
   "source": [
    "f1_score_manual = get_f1_score(optimal_k_val, get_similarity_obj_list(optimal_sim_fn, test_data_set, tf_idf_test))\n",
    "accuracy_score_manual = get_accuracy_score(optimal_k_val, get_similarity_obj_list(optimal_sim_fn, test_data_set, tf_idf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15000352",
   "metadata": {},
   "source": [
    "### Train and test Sklearn's KNN classifier model on your data (use metric which gave best results on your experimentation with built-from-scratch model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aab7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(optimal_k_val, metric=\"cosine\")\n",
    "knn.fit(tf_idf_train, train_data_set['label'])\n",
    "pred = knn.predict(tf_idf_test)\n",
    "f1_score_skl = metrics.f1_score(test_data_set['label'], pred, pos_label='spam')\n",
    "accuracy_score_skl = metrics.accuracy_score(test_data_set['label'], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22aa47",
   "metadata": {},
   "source": [
    "***Compare both the models result.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually calculated F1 score 0.8644067796610169\n",
      "SKLearn calculated F1 score 0.869198312236287\n",
      "Manually calculated F1 score 0.9712746858168761\n",
      "SKLearn calculated F1 score 0.9721723518850988\n"
     ]
    }
   ],
   "source": [
    "print(\"Manually calculated F1 score\", f1_score_manual)\n",
    "print(\"SKLearn calculated F1 score\", f1_score_skl)\n",
    "print(\"Manually calculated F1 score\", accuracy_score_manual)\n",
    "print(\"SKLearn calculated F1 score\", accuracy_score_skl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64987575",
   "metadata": {},
   "source": [
    "***What is the time complexity of training using KNN classifier?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770c106",
   "metadata": {},
   "source": [
    "<p>\n",
    "For training data set, the time complexity of KNN is O(1) as no actual training is done, KNN is a brute force algorithm\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1f345",
   "metadata": {},
   "source": [
    "***What is the time complexity while testing? Is KNN a linear classifier or can it learn any boundary?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daaa324",
   "metadata": {},
   "source": [
    "<p>\n",
    "Time complexity while testing is O(n*d) where <br>\n",
    "n is the number of emails <br>\n",
    "d is the number of different words available <br>\n",
    "\n",
    "A classifier is linear if its decision boundary on the feature space is a linear function: positive and negative examples are separated by an hyperplane.<br> <br>\n",
    "\n",
    "With KNN you don't have an hyperplane in general. Imagine some dense region of positive points. The decision boundary to classify test instances around those points will look like a curve - not a hyperplane, thus KNN is not a linear classifier\n",
    "<br>\n",
    "KNN classifier can learn any boundary.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465c6c2",
   "metadata": {},
   "source": [
    "**Why accuracy alone is not sufficient to evaluate the model. Why we need precision/recall/f1-score?**\n",
    "\n",
    "- We can see that accuracy alone does not paint the whole picture. We cannot know how well the model performs if e are more concerned with either false positives or false negatives. In such senario only accuracy fails to summarize the effectiveness of the model. \n",
    "- When we have imbalanced data and we need high true positives, precision is prefered metrics. Because precision has no false negative in its formula, which can impact the positive rate, it can help us to identity how accurate our model is in identifing true positive cases over all positive cases.\n",
    "- When we are more concerned with false negatives, recall is a better metrics to use.\n",
    "- There is a tradeoff between precision and recall. As precision increases, recall decreases and vice versa \n",
    "- We need a tradeoff between Precision and Recall. We first need to decide which is more important for our classification problem. There are also a lot of situations where both precision and recall are equally important. If we want to create a classification model with the optimal balance of recall and precision, then we try to maximize the F1 score.\n",
    "- The F1 score is the harmonic mean of precision and recall, taking both metrics into account"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
